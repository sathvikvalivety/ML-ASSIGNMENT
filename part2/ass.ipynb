{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow scikit-image opencv-python scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "from skimage import exposure\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten labels\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class names for CIFAR-10\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(x_train[i])\n",
    "    plt.title(class_names[y_train[i]])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess images: Convert to grayscale and resize\n",
    "def preprocess_images(images, size=(32, 32)):\n",
    "    processed_images = []\n",
    "    for img in images:\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        resized_img = cv2.resize(gray_img, size)\n",
    "        processed_images.append(resized_img)\n",
    "    return np.array(processed_images)\n",
    "\n",
    "x_train_processed = preprocess_images(x_train)\n",
    "x_test_processed = preprocess_images(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values\n",
    "x_train_processed = x_train_processed / 255.0\n",
    "x_test_processed = x_test_processed / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display preprocessed images\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(x_train_processed[i], cmap='gray')\n",
    "    plt.title(class_names[y_train[i]])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Histogram of Oriented Gradients (HOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract HOG features\n",
    "def extract_hog_features(images):\n",
    "    hog_features = []\n",
    "    for img in images:\n",
    "        fd, hog_image = hog(img, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True, channel_axis=None)\n",
    "        hog_features.append(fd)\n",
    "    return np.array(hog_features)\n",
    "\n",
    "x_train_hog = extract_hog_features(x_train_processed)\n",
    "x_test_hog = extract_hog_features(x_test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display HOG features for a sample image\n",
    "sample_hog, hog_image = hog(x_train_processed[0], pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True, channel_axis=None)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(x_train_processed[0], cmap='gray')\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(hog_image, cmap='gray')\n",
    "plt.title('HOG Features')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 3.2 Local Binary Patterns (LBP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract LBP features\n",
    "def extract_lbp_features(images, P=8, R=1):\n",
    "    lbp_features = []\n",
    "    for img in images:\n",
    "        lbp = local_binary_pattern(img, P=P, R=R, method=\"uniform\")\n",
    "        hist, _ = np.histogram(lbp, bins=np.arange(0, P + 3), range=(0, P + 2))\n",
    "        hist = hist.astype(\"float\")\n",
    "        hist /= (hist.sum() + 1e-6)  # Normalize\n",
    "        lbp_features.append(hist)\n",
    "    return np.array(lbp_features)\n",
    "\n",
    "x_train_lbp = extract_lbp_features(x_train_processed)\n",
    "x_test_lbp = extract_lbp_features(x_test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display LBP features for a sample image\n",
    "sample_lbp = local_binary_pattern(x_train_processed[0], P=8, R=1, method=\"uniform\")\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(x_train_processed[0], cmap='gray')\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(sample_lbp, cmap='gray')\n",
    "plt.title('LBP Features')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Edge Detection (Canny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_edge_features(images):\n",
    "    edge_features = []\n",
    "    for img in images:\n",
    "        # Scale image back to [0, 255] and convert to 8-bit unsigned integer\n",
    "        img_scaled = (img * 255).astype(np.uint8)\n",
    "        edges = cv2.Canny(img_scaled, threshold1=100, threshold2=200)\n",
    "        edge_features.append(edges.flatten())\n",
    "    return np.array(edge_features)\n",
    "\n",
    "x_train_edges = extract_edge_features(x_train_processed)\n",
    "x_test_edges = extract_edge_features(x_test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Edge features for a sample image\n",
    "sample_edges = cv2.Canny((x_train_processed[0] * 255).astype(np.uint8), threshold1=100, threshold2=200)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(x_train_processed[0], cmap='gray')\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(sample_edges, cmap='gray')\n",
    "plt.title('Edge Features')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4 Deep Learning-Based Feature Extraction (ResNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained ResNet50 model\n",
    "base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(32, 32, 3))\n",
    "model = Model(inputs=base_model.input, outputs=base_model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess images for ResNet\n",
    "x_train_resnet = preprocess_input(x_train)\n",
    "x_test_resnet = preprocess_input(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features\n",
    "x_train_resnet_features = model.predict(x_train_resnet)\n",
    "x_test_resnet_features = model.predict(x_test_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten features\n",
    "x_train_resnet_features = x_train_resnet_features.reshape(x_train_resnet_features.shape[0], -1)\n",
    "x_test_resnet_features = x_test_resnet_features.reshape(x_test_resnet_features.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Train and Evaluate Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 Logistic Regression on HOG Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train classifier\n",
    "clf_hog = LogisticRegression(max_iter=1000)\n",
    "clf_hog.fit(x_train_hog, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "y_pred_hog = clf_hog.predict(x_test_hog)\n",
    "print(\"HOG + Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_hog))\n",
    "print(classification_report(y_test, y_pred_hog, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm_hog = confusion_matrix(y_test, y_pred_hog)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_hog, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix: HOG + Logistic Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 KNN on LBP Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train KNN classifier on LBP features\n",
    "clf_lbp = KNeighborsClassifier(n_neighbors=5)  # Define the KNN classifier\n",
    "clf_lbp.fit(x_train_lbp, y_train)  # Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the classifier\n",
    "y_pred_lbp = clf_lbp.predict(x_test_lbp)  # Predict on the test data\n",
    "print(\"LBP + KNN Accuracy:\", accuracy_score(y_test, y_pred_lbp))  # Print accuracy\n",
    "print(classification_report(y_test, y_pred_lbp, target_names=class_names))  # Print classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm_lbp = confusion_matrix(y_test, y_pred_lbp)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_lbp, annot=True, fmt='d', cmap='Greens', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix: LBP + KNN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3 Random Forest on Edge Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train classifier\n",
    "clf_edges = RandomForestClassifier(n_estimators=100)\n",
    "clf_edges.fit(x_train_edges, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "y_pred_edges = clf_edges.predict(x_test_edges)\n",
    "print(\"Edge Detection + Random Forest Accuracy:\", accuracy_score(y_test, y_pred_edges))\n",
    "print(classification_report(y_test, y_pred_edges, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm_edges = confusion_matrix(y_test, y_pred_edges)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_edges, annot=True, fmt='d', cmap='Reds', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix: Edge Detection + Random Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4 Logistic Regression on ResNet Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train classifier\n",
    "clf_resnet = LogisticRegression(max_iter=1000)\n",
    "clf_resnet.fit(x_train_resnet_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "y_pred_resnet = clf_resnet.predict(x_test_resnet_features)\n",
    "print(\"ResNet + Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_resnet))\n",
    "print(classification_report(y_test, y_pred_resnet, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm_resnet = confusion_matrix(y_test, y_pred_resnet)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_resnet, annot=True, fmt='d', cmap='Purples', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix: ResNet + Logistic Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hybrid Feature Fusion: HOG + ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Extract HOG features (as before)\n",
    "x_train_hog = extract_hog_features(x_train_processed)  # (50000, n_hog_features)\n",
    "x_test_hog = extract_hog_features(x_test_processed)    # (10000, n_hog_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Extract ResNet features (as before)\n",
    "x_train_resnet_features = model.predict(x_train_resnet).reshape(x_train_resnet.shape[0], -1)\n",
    "x_test_resnet_features = model.predict(x_test_resnet).reshape(x_test_resnet.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Combine features horizontally\n",
    "x_train_hybrid = np.hstack([x_train_hog, x_train_resnet_features])  # (50000, n_hog + 2048)\n",
    "x_test_hybrid = np.hstack([x_test_hog, x_test_resnet_features])     # (10000, n_hog + 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Normalize and reduce dimensionality (optional but recommended)\n",
    "pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    PCA(n_components=128)  # Reduce to 128 dimensions for efficiency\n",
    ")\n",
    "x_train_hybrid = pipeline.fit_transform(x_train_hybrid)\n",
    "x_test_hybrid = pipeline.transform(x_test_hybrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Train a classifier on hybrid features\n",
    "clf_hybrid = LogisticRegression(max_iter=1000)  # Or use RandomForest/SVM\n",
    "clf_hybrid.fit(x_train_hybrid, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Evaluate\n",
    "y_pred_hybrid = clf_hybrid.predict(x_test_hybrid)\n",
    "print(\"Hybrid (HOG+ResNet) Accuracy:\", accuracy_score(y_test, y_pred_hybrid))\n",
    "print(classification_report(y_test, y_pred_hybrid, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_hybrid), \n",
    "            annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix: Hybrid (HOG+ResNet)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamic Feature Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Multiply, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Separate normalization for each feature type\n",
    "hog_scaler = StandardScaler()\n",
    "resnet_scaler = StandardScaler()\n",
    "\n",
    "x_train_hog_scaled = hog_scaler.fit_transform(x_train_hog)\n",
    "x_train_resnet_scaled = resnet_scaler.fit_transform(x_train_resnet_features)\n",
    "\n",
    "x_test_hog_scaled = hog_scaler.transform(x_test_hog)\n",
    "x_test_resnet_scaled = resnet_scaler.transform(x_test_resnet_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Dynamic Feature Selection Model\n",
    "def build_dynamic_fusion_model(hog_dim, resnet_dim, num_classes):\n",
    "    hog_input = Input(shape=(hog_dim,), name='hog_input')\n",
    "    resnet_input = Input(shape=(resnet_dim,), name='resnet_input')\n",
    "    \n",
    "    # Attention mechanism\n",
    "    attention = Dense(hog_dim, activation='sigmoid', name='attention')(resnet_input)\n",
    "    weighted_hog = Multiply(name='feature_weighting')([hog_input, attention])\n",
    "    \n",
    "    # Concatenate\n",
    "    combined = Concatenate(name='feature_fusion')([weighted_hog, resnet_input])\n",
    "    \n",
    "    # Classification\n",
    "    outputs = Dense(num_classes, activation='softmax', name='output')(combined)\n",
    "    \n",
    "    return Model(inputs=[hog_input, resnet_input], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Build model\n",
    "model = build_dynamic_fusion_model(\n",
    "    hog_dim=x_train_hog_scaled.shape[1], \n",
    "    resnet_dim=x_train_resnet_scaled.shape[1], \n",
    "    num_classes=10\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Train with validation\n",
    "history = model.fit(\n",
    "    [x_train_hog_scaled, x_train_resnet_scaled],\n",
    "    y_train,\n",
    "    epochs=15,\n",
    "    batch_size=256,\n",
    "    validation_data=([x_test_hog_scaled, x_test_resnet_scaled], y_test),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Evaluation\n",
    "test_loss, test_acc = model.evaluate([x_test_hog_scaled, x_test_resnet_scaled], y_test)\n",
    "print(f\"\\nTest Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Visualization\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Attention visualization (for one sample)\n",
    "sample_idx = 10  # Change to see different examples\n",
    "attention_model = Model(inputs=model.inputs, outputs=model.get_layer('attention').output)\n",
    "attention_weights = attention_model.predict([x_test_hog_scaled[sample_idx:sample_idx+1], \n",
    "                                          x_test_resnet_scaled[sample_idx:sample_idx+1]])\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.bar(range(x_train_hog_scaled.shape[1]), attention_weights.flatten())\n",
    "plt.title(f'Attention Weights for {class_names[y_test[sample_idx]]} (True) vs {class_names[np.argmax(model.predict([x_test_hog_scaled[sample_idx:sample_idx+1], x_test_resnet_scaled[sample_idx:sample_idx+1]]))]} (Predicted)')\n",
    "plt.xlabel('HOG Feature Index')\n",
    "plt.ylabel('Attention Weight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
